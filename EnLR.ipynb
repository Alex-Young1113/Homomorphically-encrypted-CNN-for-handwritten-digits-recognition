{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Outcome']\n",
    "X = df.drop('Outcome', axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m y_train \u001b[39m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m y_test \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlen\u001b[39m(X):\n\u001b[1;32m      9\u001b[0m     rand \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandom()\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m rand \u001b[39m>\u001b[39m \u001b[39m0.2\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "## Splitting for X and Y variables:\n",
    "## Splitting dataset into 80% Training and 20% Testing Data:\n",
    "import random\n",
    "import sklearn\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in len(X):\n",
    "    rand = random.random()\n",
    "    if rand > 0.2:\n",
    "        X_train.append(X[i])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8, random_state =0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "X_test = torch.from_numpy(X_test.values).float()\n",
    "y_train = torch.from_numpy(y_train.values).long()\n",
    "y_test = torch.from_numpy(y_test.values).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_i, n_o):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear = nn.Linear(n_i, n_o)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "model = MLP(X_train.shape[1], y_train.unique().size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss = 4.2837\n",
      "epoch: 200, loss = 2.2890\n",
      "epoch: 300, loss = 1.5422\n",
      "epoch: 400, loss = 0.9820\n",
      "epoch: 500, loss = 0.7318\n",
      "epoch: 600, loss = 0.6411\n",
      "epoch: 700, loss = 0.6161\n",
      "epoch: 800, loss = 0.6085\n",
      "epoch: 900, loss = 0.6030\n",
      "epoch: 1000, loss = 0.5977\n",
      "epoch: 1100, loss = 0.5924\n",
      "epoch: 1200, loss = 0.5873\n",
      "epoch: 1300, loss = 0.5823\n",
      "epoch: 1400, loss = 0.5775\n",
      "epoch: 1500, loss = 0.5728\n",
      "epoch: 1600, loss = 0.5682\n",
      "epoch: 1700, loss = 0.5638\n",
      "epoch: 1800, loss = 0.5596\n",
      "epoch: 1900, loss = 0.5555\n",
      "epoch: 2000, loss = 0.5515\n",
      "epoch: 2100, loss = 0.5478\n",
      "epoch: 2200, loss = 0.5442\n",
      "epoch: 2300, loss = 0.5407\n",
      "epoch: 2400, loss = 0.5374\n",
      "epoch: 2500, loss = 0.5342\n",
      "epoch: 2600, loss = 0.5312\n",
      "epoch: 2700, loss = 0.5283\n",
      "epoch: 2800, loss = 0.5256\n",
      "epoch: 2900, loss = 0.5230\n",
      "epoch: 3000, loss = 0.5205\n",
      "epoch: 3100, loss = 0.5181\n",
      "epoch: 3200, loss = 0.5158\n",
      "epoch: 3300, loss = 0.5137\n",
      "epoch: 3400, loss = 0.5117\n",
      "epoch: 3500, loss = 0.5097\n",
      "epoch: 3600, loss = 0.5079\n",
      "epoch: 3700, loss = 0.5062\n",
      "epoch: 3800, loss = 0.5045\n",
      "epoch: 3900, loss = 0.5029\n",
      "epoch: 4000, loss = 0.5015\n",
      "epoch: 4100, loss = 0.5001\n",
      "epoch: 4200, loss = 0.4988\n",
      "epoch: 4300, loss = 0.4975\n",
      "epoch: 4400, loss = 0.4964\n",
      "epoch: 4500, loss = 0.4953\n",
      "epoch: 4600, loss = 0.4943\n",
      "epoch: 4700, loss = 0.4933\n",
      "epoch: 4800, loss = 0.4924\n",
      "epoch: 4900, loss = 0.4916\n",
      "epoch: 5000, loss = 0.4908\n",
      "epoch: 5100, loss = 0.4901\n",
      "epoch: 5200, loss = 0.4895\n",
      "epoch: 5300, loss = 0.4888\n",
      "epoch: 5400, loss = 0.4883\n",
      "epoch: 5500, loss = 0.4877\n",
      "epoch: 5600, loss = 0.4872\n",
      "epoch: 5700, loss = 0.4867\n",
      "epoch: 5800, loss = 0.4864\n",
      "epoch: 5900, loss = 0.4860\n",
      "epoch: 6000, loss = 0.4856\n",
      "epoch: 6100, loss = 0.4854\n",
      "epoch: 6200, loss = 0.4850\n",
      "epoch: 6300, loss = 0.4849\n",
      "epoch: 6400, loss = 0.4845\n",
      "epoch: 6500, loss = 0.4844\n",
      "epoch: 6600, loss = 0.4842\n",
      "epoch: 6700, loss = 0.4841\n",
      "epoch: 6800, loss = 0.4839\n",
      "epoch: 6900, loss = 0.4837\n",
      "epoch: 7000, loss = 0.4838\n",
      "epoch: 7100, loss = 0.4835\n",
      "epoch: 7200, loss = 0.4835\n",
      "epoch: 7300, loss = 0.4835\n",
      "epoch: 7400, loss = 0.4833\n",
      "epoch: 7500, loss = 0.4834\n",
      "epoch: 7600, loss = 0.4832\n",
      "epoch: 7700, loss = 0.4833\n",
      "epoch: 7800, loss = 0.4832\n",
      "epoch: 7900, loss = 0.4831\n",
      "epoch: 8000, loss = 0.4832\n",
      "epoch: 8100, loss = 0.4831\n",
      "epoch: 8200, loss = 0.4832\n",
      "epoch: 8300, loss = 0.4831\n",
      "epoch: 8400, loss = 0.4831\n",
      "epoch: 8500, loss = 0.4831\n",
      "epoch: 8600, loss = 0.4831\n",
      "epoch: 8700, loss = 0.4832\n",
      "epoch: 8800, loss = 0.4831\n",
      "epoch: 8900, loss = 0.4832\n",
      "epoch: 9000, loss = 0.4830\n",
      "epoch: 9100, loss = 0.4830\n",
      "epoch: 9200, loss = 0.4831\n",
      "epoch: 9300, loss = 0.4830\n",
      "epoch: 9400, loss = 0.4831\n",
      "epoch: 9500, loss = 0.4830\n",
      "epoch: 9600, loss = 0.4831\n",
      "epoch: 9700, loss = 0.4830\n",
      "epoch: 9800, loss = 0.4830\n",
      "epoch: 9900, loss = 0.4831\n",
      "epoch: 10000, loss = 0.4830\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    loss_mean = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_mean += loss.item()\n",
    "        if (epoch+1) % 100 == 0:                                         \n",
    "            print(f'epoch: {epoch+1}, loss = {loss_mean / 100:.4f}')\n",
    "            loss_mean = 0.0\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8247\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(X_test)\n",
    "    #y_pred = nn.Softmax(dim=1)(logits)\n",
    "    y_predicted_cls = logits.argmax(1)\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12246307730674744, 0.06274420022964478, -0.05025584623217583, 0.04181673377752304, 0.1361420452594757, -0.05460747331380844, -0.4560495615005493, -0.12040003389120102]\n",
      "[-0.03104415349662304, 0.09664390236139297, -0.0640219897031784, 0.04624515026807785, 0.13472746312618256, 0.03315586969256401, 0.43858933448791504, -0.10050632804632187]\n",
      "[4.125000953674316, -4.053066253662109]\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight.data.tolist()[0])\n",
    "print(model.linear.weight.data.tolist()[1])\n",
    "print(model.linear.bias.data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnprMLP:\n",
    "    def __init__(self, model):\n",
    "        self.weight = model.linear.weight.data.tolist()\n",
    "        self.bias = model.linear.bias.data.tolist()\n",
    "    def forward(self, enc_x):\n",
    "        enc_out = []\n",
    "        for i in range(len(self.bias)):\n",
    "            enc_out.append(enc_x.dot(self.weight[i]) + self.bias[i])\n",
    "        return enc_out\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "\n",
    "enprmlp = EnprMLP(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_X_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in X_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated test_set of 154 entries in 0 seconds\n",
      "accuracy: 0.8052\n"
     ]
    }
   ],
   "source": [
    "def enc_evaluation(model, enc_X_test, y_test):\n",
    "    t_start = time()\n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_X_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        # plain comparaison\n",
    "        out = []\n",
    "        for x in enc_out:\n",
    "            out.append(x.decrypt())\n",
    "        y_predicted_cls = np.array(out).argmax()\n",
    "        if y == y_predicted_cls:\n",
    "            correct += 1\n",
    "    \n",
    "\n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(y_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f'accuracy: {(correct / len(y_test)):.4f}')\n",
    "\n",
    "enc_evaluation(enprmlp, enc_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntrMLP:\n",
    "    def __init__(self, model):\n",
    "        self.weight = model.linear.weight.data.tolist()\n",
    "        self.bias = model.linear.bias.data.tolist()\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    def forward(self, enc_x):\n",
    "        enc_out = []\n",
    "        for i in range(len(self.bias)):\n",
    "            enc_out.append(enc_x.dot(self.weight[i]) + self.bias[i])\n",
    "        return self.softmax(enc_out)\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    def encrypt(self, context):\n",
    "        self.weight = [ts.ckks_vector(context, w) for w in self.weight]\n",
    "        self.bias = [ts.ckks_vector(context, [b]) for b in self.bias]\n",
    "    def decrypt(self):\n",
    "        self.weight = [w.decrypt() for w in self.weight]\n",
    "        self.bias = [b.decrypt()[0] for b in self.bias]\n",
    "    def exp(self, enc_x):\n",
    "        return enc_x.polyval([1, 1])\n",
    "        #return enc_x.polyval([1, 1, 1/2, 1/6, 1/24, 1/120])\n",
    "    def ln(self, enc_x):\n",
    "        enc_x -= 1\n",
    "        return enc_x.polyval([0, 1])\n",
    "        #return enc_x.polyval([0, 1, -1/2, 1/3, -1/4, 1/5])\n",
    "    def softmax(self, enc_x):\n",
    "        return (enc_x[1] - enc_x[0]).polyval([0.5, 0.197, 0, -0.004])\n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "    def update_parameters(self):\n",
    "        if(self._count == 0):\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        self.weight[1] -= self._delta_w * (1 / self._count)\n",
    "        self.bias[1] -= self._delta_b * (1 / self._count)\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "ctx_tr = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_tr.global_scale = 2 ** 21\n",
    "ctx_tr.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train[0].tolist()))\n",
    "print(type([y_train[0].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 10 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_X_train = [ts.ckks_vector(ctx_tr, x.tolist()) for x in X_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_tr, [y.tolist()]) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average time per epoch: 63 seconds\n"
     ]
    }
   ],
   "source": [
    "entrmlp = EntrMLP(model)\n",
    "entrmlp.encrypt(ctx_tr)\n",
    "accuracy = 0\n",
    "times = []\n",
    "for epoch in range(1):\n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_X_train, enc_y_train):\n",
    "        enc_out = entrmlp.forward(enc_x)\n",
    "        entrmlp.backward(enc_x, enc_out, enc_y)\n",
    "    entrmlp.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, enc_X_test, y_test):\n",
    "    t_start = time()\n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_X_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        out = model(enc_x).decrypt()\n",
    "        print(y)\n",
    "        print(out[0])\n",
    "        if abs(y - out[0]) < 0.5:\n",
    "            correct += 1\n",
    "    \n",
    "\n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(y_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f'accuracy: {(correct / len(y_test)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "1030278498280.4307\n",
      "tensor(0)\n",
      "665585283372.8848\n",
      "tensor(0)\n",
      "89735011852.45557\n",
      "tensor(1)\n",
      "2359371404371.2783\n",
      "tensor(0)\n",
      "210048474311.1577\n",
      "tensor(0)\n",
      "205661376525.98605\n",
      "tensor(1)\n",
      "2036134581141.7969\n",
      "tensor(1)\n",
      "2473640026045.767\n",
      "tensor(0)\n",
      "2701918766682.0874\n",
      "tensor(0)\n",
      "1459253745699.1123\n",
      "tensor(1)\n",
      "3232877916665.942\n",
      "tensor(1)\n",
      "3597638943608.3716\n",
      "tensor(0)\n",
      "271601086829.07074\n",
      "tensor(0)\n",
      "466340368028.04675\n",
      "tensor(0)\n",
      "89729206122.71912\n",
      "tensor(0)\n",
      "219611380843.20102\n",
      "tensor(1)\n",
      "2058347308919.2969\n",
      "tensor(0)\n",
      "70735462643.14392\n",
      "tensor(0)\n",
      "452922567060.08856\n",
      "tensor(0)\n",
      "472936396119.483\n",
      "tensor(1)\n",
      "500321490409.5231\n",
      "tensor(1)\n",
      "270140076905.46887\n",
      "tensor(0)\n",
      "81581094949.03813\n",
      "tensor(0)\n",
      "92797529933.1774\n",
      "tensor(0)\n",
      "744942039554.8658\n",
      "tensor(0)\n",
      "293417113613.16675\n",
      "tensor(0)\n",
      "182877304146.99838\n",
      "tensor(0)\n",
      "1799667110787.1511\n",
      "tensor(0)\n",
      "224553615853.93546\n",
      "tensor(0)\n",
      "209711908203.09448\n",
      "tensor(0)\n",
      "1362096648868.021\n",
      "tensor(0)\n",
      "508676279800.5748\n",
      "tensor(0)\n",
      "659782899444.5242\n",
      "tensor(0)\n",
      "1262731291328.2493\n",
      "tensor(0)\n",
      "415648166544.9888\n",
      "tensor(1)\n",
      "613108938496.4106\n",
      "tensor(1)\n",
      "1349871279717.5579\n",
      "tensor(0)\n",
      "589335912362.3191\n",
      "tensor(0)\n",
      "525273427495.71204\n",
      "tensor(0)\n",
      "1280340985953.8247\n",
      "tensor(0)\n",
      "688264240134.5388\n",
      "tensor(0)\n",
      "146954215001.70682\n",
      "tensor(0)\n",
      "341036921812.8463\n",
      "tensor(1)\n",
      "900638207099.7504\n",
      "tensor(1)\n",
      "14803034292437.582\n",
      "tensor(0)\n",
      "166772324749.76086\n",
      "tensor(0)\n",
      "402730390367.8444\n",
      "tensor(1)\n",
      "973257405480.1912\n",
      "tensor(1)\n",
      "685910778271.7141\n",
      "tensor(1)\n",
      "304275884385.38293\n",
      "tensor(0)\n",
      "339638350221.02515\n",
      "tensor(0)\n",
      "420512739132.9699\n",
      "tensor(1)\n",
      "3621438609257.714\n",
      "tensor(0)\n",
      "468631125919.1754\n",
      "tensor(0)\n",
      "1330976975260.7349\n",
      "tensor(0)\n",
      "1639189574.3563204\n",
      "tensor(0)\n",
      "132761182008.55246\n",
      "tensor(1)\n",
      "303707056504.77203\n",
      "tensor(1)\n",
      "329418953161.3909\n",
      "tensor(1)\n",
      "134797152239.12657\n",
      "tensor(1)\n",
      "3678348224798.657\n",
      "tensor(0)\n",
      "3760839783126.7925\n",
      "tensor(0)\n",
      "267904612290.0852\n",
      "tensor(1)\n",
      "257250090272.168\n",
      "tensor(1)\n",
      "736420046759.1069\n",
      "tensor(1)\n",
      "920431938712.1238\n",
      "tensor(1)\n",
      "662273187886.4294\n",
      "tensor(0)\n",
      "292812469812.16266\n",
      "tensor(0)\n",
      "193058205479.38657\n",
      "tensor(0)\n",
      "110700876225.53072\n",
      "tensor(0)\n",
      "190335555463.64865\n",
      "tensor(0)\n",
      "176373953101.6935\n",
      "tensor(0)\n",
      "140934550692.014\n",
      "tensor(0)\n",
      "879996874026.2004\n",
      "tensor(1)\n",
      "644725406185.3564\n",
      "tensor(0)\n",
      "388145511483.1517\n",
      "tensor(0)\n",
      "259455741944.69284\n",
      "tensor(0)\n",
      "2353032137361.5576\n",
      "tensor(0)\n",
      "143714356531.28674\n",
      "tensor(0)\n",
      "197151650193.76855\n",
      "tensor(0)\n",
      "202851245614.53287\n",
      "tensor(0)\n",
      "2133282323338.6748\n",
      "tensor(0)\n",
      "869355978710.79\n",
      "tensor(0)\n",
      "418441272028.056\n",
      "tensor(0)\n",
      "168061484440.53394\n",
      "tensor(0)\n",
      "163745947970.01254\n",
      "tensor(1)\n",
      "326870935594.5908\n",
      "tensor(0)\n",
      "487911238780.46295\n",
      "tensor(1)\n",
      "3132863776095.004\n",
      "tensor(0)\n",
      "633599638615.6729\n",
      "tensor(0)\n",
      "323236635454.25305\n",
      "tensor(0)\n",
      "328088654829.9856\n",
      "tensor(0)\n",
      "541571137415.8179\n",
      "tensor(0)\n",
      "488982532064.9046\n",
      "tensor(0)\n",
      "1229538795849.831\n",
      "tensor(0)\n",
      "371899827161.1853\n",
      "tensor(1)\n",
      "569486583118.671\n",
      "tensor(0)\n",
      "3667052805785.007\n",
      "tensor(1)\n",
      "1831868529368.1233\n",
      "tensor(1)\n",
      "262785678887.89038\n",
      "tensor(0)\n",
      "2834750087903.983\n",
      "tensor(0)\n",
      "469792689447.79376\n",
      "tensor(0)\n",
      "253010060796.7253\n",
      "tensor(0)\n",
      "246840621656.15634\n",
      "tensor(0)\n",
      "343329332346.49457\n",
      "tensor(1)\n",
      "211596131002.02164\n",
      "tensor(0)\n",
      "1025251309766.2834\n",
      "tensor(0)\n",
      "393710362334.869\n",
      "tensor(0)\n",
      "393554194408.07227\n",
      "tensor(1)\n",
      "711289868605.994\n",
      "tensor(0)\n",
      "161845522008.01566\n",
      "tensor(1)\n",
      "1399361660964.3425\n",
      "tensor(1)\n",
      "421854473792.24097\n",
      "tensor(1)\n",
      "716108579717.5845\n",
      "tensor(1)\n",
      "9940591597397.242\n",
      "tensor(1)\n",
      "614907677578.918\n",
      "tensor(0)\n",
      "2252050489177.9717\n",
      "tensor(0)\n",
      "7006228554625.322\n",
      "tensor(0)\n",
      "247762378743.26535\n",
      "tensor(1)\n",
      "1361608600024.7773\n",
      "tensor(0)\n",
      "292817848448.5128\n",
      "tensor(0)\n",
      "328291711426.1267\n",
      "tensor(0)\n",
      "1058930997989.6451\n",
      "tensor(0)\n",
      "344368617356.26746\n",
      "tensor(0)\n",
      "740265809644.7511\n",
      "tensor(0)\n",
      "120298114264.15251\n",
      "tensor(0)\n",
      "1370467666036.09\n",
      "tensor(1)\n",
      "285142477409.676\n",
      "tensor(0)\n",
      "371874968385.66315\n",
      "tensor(0)\n",
      "669563395087.5168\n",
      "tensor(0)\n",
      "1340916201439.8906\n",
      "tensor(0)\n",
      "100010821629.23375\n",
      "tensor(0)\n",
      "107747220068.67412\n",
      "tensor(1)\n",
      "14341349037825.643\n",
      "tensor(0)\n",
      "455093968304.6346\n",
      "tensor(1)\n",
      "239969252093.5527\n",
      "tensor(0)\n",
      "190441110040.52664\n",
      "tensor(1)\n",
      "214920660264.17856\n",
      "tensor(1)\n",
      "268338781407.70648\n",
      "tensor(0)\n",
      "234594676317.5047\n",
      "tensor(0)\n",
      "257625880897.2667\n",
      "tensor(0)\n",
      "1513190586677.5164\n",
      "tensor(0)\n",
      "166163125860.06378\n",
      "tensor(0)\n",
      "76834506984.77032\n",
      "tensor(1)\n",
      "248463898620.13443\n",
      "tensor(0)\n",
      "151401794051.05032\n",
      "tensor(0)\n",
      "189796899381.40488\n",
      "tensor(0)\n",
      "126076094650.67857\n",
      "tensor(0)\n",
      "163500883722.17505\n",
      "tensor(1)\n",
      "1442336193557.8845\n",
      "tensor(0)\n",
      "242145968437.87552\n",
      "tensor(1)\n",
      "430857118126.4648\n",
      "tensor(0)\n",
      "747146946570.0171\n",
      "tensor(0)\n",
      "554850794355.4442\n",
      "Evaluated test_set of 154 entries in 13 seconds\n",
      "accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "entrmlp.decrypt()\n",
    "entrmlp.encrypt(ctx_tr)\n",
    "enc_X_test = [ts.ckks_vector(ctx_tr, x.tolist()) for x in X_test]\n",
    "evaluation(entrmlp, enc_X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
